---
title: "2021년 10월 07일 TIL"
date: 2021-10-07 00:23:00 -0400
categories: TIL
---

특화프로젝트 발표일 D-1

최종적으로 목표했던 기능들의 구현에 성공했다. 개선해야할 점들이 많지만, 그럼에도 아무런 결과물도 완성하지 못하지 않을까 싶었던 이번 프로젝트도 어떻게든 해낸 점이 뿌듯한 것 같다. 취준 기간과 겹쳐서 프로젝트 내내 3~4시간을 간신히 잔 것 같은데, 고생이 보답받은 것 같아서 기쁘다.

나의 경우에는, 이번 프로젝트에서 Kafka의 학습에 의의를 두고 진행한 프로젝트였다. LINE 기술블로그를 탐방하다가 우연히 마주친

https://engineering.linecorp.com/ko/blog/line-shopping-platform-kafka-mongodb-kubernetes/

글들을 보고 이번 프로젝트에서 이 기술을 한번 도입해보고, 학습해봐야겠다고 다짐했었다.

원래도 Kafka에 대해서 익히 들어왔지만 도대체 그게 뭐길래 좋다고 하는거지? 정도의 생각만 갖고 있었고, 이게 주니어가 건드릴만한 영역의 기술일까? 아직 나는 자바도, SpringBoot에 대한 이해도 부족한 것 같은데 다른 것에 손을 벌리는 것이 맞는 행동일까라는 생각을 했지만 결국 이러한 것들도 도전이라고 생각했다. 나에게 있어서 도전은 삶의 가장 중요한 기치 중 하나이고, 이것이 나의 역량을 넘어서는 도전이어서 실패하더라도, 그 실패의 과정에서 얻는 것들이 또 귀한 경험이 되지 않을까 싶었다.

플러스 알파로는, SSAFY에서 제공해주는 서버가 있을 때 시도해봐야하지 않겠냐는 생각도 머리 속에 있었다. 생각보다 Kafka를 돌리기 위해서 필요한 요구 스펙이 높았고, 최소 AWS 기준 Medium 사이즈의 EC2를 결제했어야할 것 같았는데, SSAFY 과정이 끝나고 나면 그것을 내 돈으로 결제하여 진행하기에는 조금 무리가 있지 않을까 싶었다.

결론은 Kafka를 도입해보는 것을 시도하였고, 아무도 가르쳐주는 사람 없이(SSAFY에 Kafka에 대한 지식이 있는 사람이 전무했다) 공식 문서를 참조하고, 기술 블로그들을 참조하며 대략적인 아키텍처를 파악하고, 인프라를 구축하고

(사실 이것에도 엄청나게 우여곡절이 많았다. 처음에는 Kafka 관련 인프라를 어떤 방식으로 구축해야할지 감이 오지 않았고, 어떻게 관리해야할지도 몰라서 Apache Kafka를 하나 생으로 다운받아 zookeeper랑 두개만 달랑 올려둔 채로 topic에 데이터를 넣었다 빼는 예제를 실행해보고, 그 다음에는, docker로 Kafka를 올리고, 그 다음에는 docker compose를 통해 Schema Registry와 기타 서버들을 묶어서 올렸다가, 나중에는 confluent platform을 통해 그것들을 일괄관리할 수 있다는 것을 알고 그간의 헤딩을 슬퍼하면서 confluent platform으로 수정했다.)

그 와중에 HDFS에 Hive를 올려 데이터 처리를 해주겠다고 한 팀원이 그것을 실패했고, 못할 것 같다고 나에게 이야기를 해온 시점이 프로젝트 종료 2주전이었다. 내가 모든 API 서버와 Kafka 관련 업무를 맡고 있던 상황에서 청천벽력같은 이야기였고, (심지어 HDFS에 데이터를 적재할 방법도 마땅히 찾아주지 못한 상황이었다. )

결국 그것도 내가 넘겨받아 Kafka Streams를 통해 데이터를 처리하고, Confluent의 HDFS 3 Sink Connector로 Kafka Connect를 통해 HDFS로 데이터를 적재했다.

이것들을 처리한 시점이 일주일 전이다. 정말 밤잠을 쪼개고 밥을 걸러가며 처리했는데, 원래 이 시기에 LINE 블로그의 글처럼 K8S를 통해 배포해보고 싶었던 나에게는 정말 아까운 시간이었다.

(다만 지금와서 생각해보면, frontend 쪽에서 next.js의 사용으로 인해 메모리 사용량을 꽤 많이 사용하고 있는 상황이어서, k8s로 올리는 것을 시도했으면 메모리가 터지지 않았을까 싶다. 현재도 꽤나 아슬아슬하게 메모리를 사용하고 있는 상황이어서, 우리의 상황으로는 그렇게까지 재현할 수는 없었을 듯 하다.)

그래도 Kafka Streams를 사용해본 것은 굉장히 재미있는 경험이었다. 다만 Ksql을 제대로 이해하지 못한 채로 구현에 급급하여 예제만 확인하고 대충 이런 형식으로 굴러가는 것이겠구나, 정도로 작업한 것이라 코드가 너무 비효율적인 경향이 있다. 추후 더욱 공부가 필요할 듯 하다.



